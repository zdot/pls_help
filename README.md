What is an interface? An interface is anything which exists to represent, interpret, or manipulate some other thing which is not the interface itself. Written language is an interface. Letters are arranged in sequence to represent words, words sentences, sentences ideas. The letters aren’t themselves language, but they can be used to represent, interpret, and manipulate it. The alphabet is such a successful interface that we don’t even think of it as one. Could we improve on it? Maybe. But it works so well that we haven’t seen any essential changes to the basic letterforms of the latin alphabet in roughly five hundred years. Most of our time is spent embedding the alphabet in other, more complicated, interfaces.

The personal computer is a relatively new technology in the arc of history, but already some of it’s own interfaces feel as unquestioningly fundamental as the alphabet. Take, for example, the cursor. A news website typically contains a collection of bizarre and dystopian headlines summarizing our perpetual fall from grace. When we find something we’d like to read, we position the cursor over the appallingly irresistible headline and click. The motion and action can come about a number of ways, via a mouse, touch pad, or touch screen, depending on the device, but in every case the concept is the same: reposition the cursor to identify a point of interest, and click to take action. The cursor doesn’t have to be represented by an arrow; it doesn’t have to be moved with a mouse; and the click doesn’t have to be the consequence of a button push. The Cursor Interface is just an idea, a collection of properties. Anything which repositions a pointer on the screen and effects a click can satisfy the Cursor Interface.

Some implementations are so successful that they come to represent the interface itself. When I think of the Cursor Interface in the context of a laptop, I think of a touch pad. Why is the touch pad so successful? Because it satisfies 99.99% of our needs when interacting with a laptop. It’s easy to understand and control. It doesn’t require specialized knowledge or advanced motor skills. Most of the time all we’re doing is repositioning the cursor and clicking. That’s it. The touch pad does that very well. Occasionally, someone has a specific need which can’t easily be accomplished with a touch pad, such as a digital illustrator who might prefer an object more suited to their practice, such as a pencil or pen. Can’t draw with a touch pad? No problem; connect a stylus and tablet through Bluetooth and off you go. The beauty of abstract interfaces is the interchangeability of implementations.

Why do laptops have built-in touch pads? Because this particular implementation of the Cursor Interface is the most readily accessible to the majority of users. A built-in stylus in lieu of a touch pad wouldn’t make sense, because it appeals to a small subset of people. Every stylus operator can use a touch pad, but not every touch pad user can effectively leverage a stylus. A touch pad is essential; a stylus is an exclusive extension. Of course you could just include both, but too many bells and whistles can easily confuse the essential function of a tool. If extensibility is an option, it’s best to keep it simple. Built-in features imply indispensability, and every new feature is quite literally an existential crisis. Have I been doing it wrong this whole time? Do I need to learn how to do it this other way? Is this other way better than the old way? Is there a place for me in this new world? If the feature is a success, the pain of breaking old habits is outweighed by gains in productivity or pleasure. If the feature is a failure, well then you’ve just inflicted an existential crisis with no known resolution on untold numbers of people, and every confrontation with the new feature, passive or otherwise, is a reminder of this unresolved crisis. A neurosis is born.

Enter Apple’s touch bar. It’s built-in, so it must be important. I’ve already got a screen, but I guess I can touch this second screen, so that’s something. Except everything I can do by touching this second screen, I can also do by interacting with applications on the first screen using the touch pad. But maybe by using the touch bar, I can shave precious seconds off of adjusting the volume or brightness. Didn’t the function keys used to do that? Maybe it’s not about the volume or the brightness. Maybe it’s about something deeper. What’s wrong with me I’m sweating. Maybe if I watch the promotional video. I think I see a sound engineer moving his finger across the touch bar. The video is in black and white. That means it’s Art, and Art is Truth. It appears he is adjusting some sort of range. Is the beauty of the touch bar the ease with which I can now adjust ranges? He seems happy. Am I happy? What if I’m cool with just adjusting a slider on the first screen using the touch pad? Does my method lack the immediacy of the touch bar thereby rendering my creative output stale? Am I sacrificing emotion for precision? The touch bar is just sitting there. I’m typing this now and it seems I can make something bold either by clicking the bold icon on the first screen, or touching the bold icon on the second screen. Which one should I do? Is the whole keyboard going away? Is this what this is about? Are they easing me into this new reality one row of keys at a time? Did an iPhone fuck a Macbook one wild night on the assembly line, and by the time the pregnancy was discovered it was just too late? Is love blind? Am I loved? I feel cold. I leave my desk to buy cigarettes. The clerk hardly looks up at me. Do I exist? I study the ash on the end of my cigarette. I become a student of ash, of the passage of time, of the slow burning away of all things, the insidious creeping of death and decay. I laugh, but no sound comes out.
